(prune_llm) [ec2-user@ip-172-31-5-145 OLD.suanfamama-prune-1]$ python main.py --model baffo32/decapoda-research-llama-7B-hf --prune_method prune_mama  --sparsity_ratio 0.50 --sparsity_type unstructured --save out/llama_7b/unstructured/prune_mama/
torch 1.10.1
transformers 4.28.0
accelerate 0.18.0
# of gpus:  1
usage: main.py [-h] [--model MODEL] [--seed SEED] [--nsamples NSAMPLES] [--sparsity_ratio SPARSITY_RATIO] [--sparsity_type {unstructured,4:8,2:4}]
               [--prune_method {magnitude,wanda,sparsegpt,ablate_mag_seq,ablate_wanda_seq,ablate_mag_iter,ablate_wanda_iter,search,opposite_magnitude,mama,bias,aigc_technique1,aigc_technique2,aigc_technique3,aigc_technique4,aigc_technique5,aigc_technique6,aigc_technique7,aigc_technique8,aigc_technique9,aigc_technique10}]
               [--cache_dir CACHE_DIR] [--use_variant] [--save SAVE] [--save_model SAVE_MODEL] [--eval_zero_shot]
main.py: error: argument --prune_method: invalid choice: 'prune_mama' (choose from 'magnitude', 'wanda', 'sparsegpt', 'ablate_mag_seq', 'ablate_wanda_seq', 'ablate_mag_iter', 'ablate_wanda_iter', 'search', 'opposite_magnitude', 'mama', 'bias', 'aigc_technique1', 'aigc_technique2', 'aigc_technique3', 'aigc_technique4', 'aigc_technique5', 'aigc_technique6', 'aigc_technique7', 'aigc_technique8', 'aigc_technique9', 'aigc_technique10')
(prune_llm) [ec2-user@ip-172-31-5-145 OLD.suanfamama-prune-1]$ python main.py --model baffo32/decapoda-research-llama-7B-hf --prune_method mama  --sparsity_ratio 0.50 --sparsity_type unstructured --save out/llama_7b/unstructured/prune_mama/
torch 1.10.1
transformers 4.28.0
accelerate 0.18.0
# of gpus:  1
loading llm model baffo32/decapoda-research-llama-7B-hf
/home/ec2-user/miniconda3/envs/prune_llm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [01:41<00:00,  3.09s/it]
/home/ec2-user/miniconda3/envs/prune_llm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
use device  cuda:0
pruning starts
******************************
layer 0 sparsity 0.500000
layer 1 sparsity 0.500000
layer 2 sparsity 0.500000
layer 3 sparsity 0.500000
layer 4 sparsity 0.500000
layer 5 sparsity 0.500000
layer 6 sparsity 0.500000
layer 7 sparsity 0.500000
layer 8 sparsity 0.500000
layer 9 sparsity 0.500000
layer 10 sparsity 0.500000
layer 11 sparsity 0.500000
layer 12 sparsity 0.500000
layer 13 sparsity 0.500000
layer 14 sparsity 0.500000
layer 15 sparsity 0.500000
layer 16 sparsity 0.500000
layer 17 sparsity 0.500000
layer 18 sparsity 0.500000
layer 19 sparsity 0.500000
layer 20 sparsity 0.500000
layer 21 sparsity 0.500000
layer 22 sparsity 0.500000
layer 23 sparsity 0.500000
layer 24 sparsity 0.500000
layer 25 sparsity 0.500000
layer 26 sparsity 0.500000
layer 27 sparsity 0.500000
layer 28 sparsity 0.500000
layer 29 sparsity 0.500000
layer 30 sparsity 0.500000
layer 31 sparsity 0.500000
sparsity sanity check 0.5000
******************************
evaluating on wikitext2
nsamples 166
sample 0
sample 50
sample 100
sample 150
wikitext perplexity 17.247310638427734